{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad habits vs Education\n",
    "\n",
    "This guided project aims to explore whether there is a connection between the student population and \"bad\" habits or behaviors that may negatively impact people's health. The habits to study are:\n",
    "\n",
    "- Coffee adiction.\n",
    "- Smoking.\n",
    "- Videogames adiction.\n",
    "\n",
    "Understanding the demographic factors of this habits in a culture and the connection with the students population could help society to understand if this bad habits or missused habits are directly related to the stress faced by higher education students. Suggesting the need to restructure the current higher education programs in places where this adictions are higher. It is important to highlight that due to lack of recent research and measures in this topics the data sources are between 2019 and 2020. \n",
    "\n",
    "*Press the '↓' key* to see what python libraries we will use for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd #For reading and handling CSV files.\n",
    "import numpy as np  # For numerical operations and handling missing values.\n",
    "import matplotlib.pyplot as plt  # For creating basic visualizations.\n",
    "import seaborn as sns  # For advanced data visualization used in the infographic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content:\n",
    "1. Introduction.\n",
    "2. Load Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also feel free to visit **https://github.com/DefoNotGus/DV_assesment** To find the project's notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Data\n",
    "\n",
    "### The datasets used to study the habits are:\n",
    "\n",
    "1. **Coffee Consumption Dataset**: Lists coffee consumption by country with extensive coverage.\n",
    "- **Source**: [Kaggle](https://www.kaggle.com/datasets/nurielreuven/coffee-consumption-by-country-2022/data)  \n",
    "2. **Smoking Rates Dataset**: Provides a chronological overview of smoking rates in many countries, sourced via a Google search.\n",
    "- **Source**: [World Population Review](https://worldpopulationreview.com/country-rankings/smoking-rates-by-country)  \n",
    "3. **Gamers Market Dataset**: Self-created CSV, compiles 2019 gaming market overview in many countries, offering chronological alignment with the other datasets. \n",
    "- **Source**: [Allcorrect Games](https://allcorrectgames.com/insights/a-global-research-of-2019-games-market/)  \n",
    "\n",
    "*Press the '↓' key*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The datasets used to analyze students and enrollment data are:  \n",
    "\n",
    "1. **Education Statistics Dataset**: A massive dataset with student enrollment data by region, sourced using the World Bank DataBank tool.  \n",
    "- **Source**: [World Bank](https://databank.worldbank.org/indicator/)  \n",
    "2. **Students Dataset**: Provides country-specific enrollment data filtered to align with the habits datasets, sourced from the OECD Data Explorer.  \n",
    "- **Source**: [OECD Data Explorer](https://data-explorer.oecd.org/)  \n",
    "\n",
    "Datasets are loaded into variables using `pd.read_csv()` from the Pandas library.\n",
    "*Press the '↓' key*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the CSV files\n",
    "coffee_df = pd.read_csv('Datasets/coffee.csv')\n",
    "smoking_df = pd.read_csv('Datasets/smoking.csv')\n",
    "gamers_df = pd.read_csv('Datasets/gamers.csv')\n",
    "edstats_df = pd.read_csv('Datasets/edstats.csv')\n",
    "students_df = pd.read_csv('Datasets/students.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization Plan.\n",
    "\n",
    "Before going to the next step, it's important to display all the datasets head (first 2 columns), the size of the dataset using the method \"shape\" and list their features or column headers in order to explain the aim of each dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Coffee_df:\n",
    "This dataset contains information on coffee consumption per capita (in kilograms) for 183 countries in the years 2020 and 2016. It is useful for identifying countries with high coffee consumption. Additional details about this dataset and others can be found in the reference section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Display head (2 first rows)\n",
    "print(\"Coffee DataFrame:\",coffee_df.head(2), \"\\n\")\n",
    "\n",
    "#size and features display \n",
    "print(f\"Size:\\nRows: {coffee_df.shape[0]}, Columns: {coffee_df.shape[1]}\")\n",
    "print(\"Coffee columns:\", coffee_df.columns.tolist(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Smoking_df:\n",
    "This dataset provides smoking rates (as a percentage of the population) for 164 countries in the years 2020, 2021, and 2022. It also includes data broken down by gender (male and female). The dataset can be used to compare smoking rates across countries and analyze gender differences in cigarette consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Display head (2 first rows)\n",
    "print(\"Smoking DataFrame:\", smoking_df.head(2), \"\\n\")\n",
    "# Size and features display\n",
    "print(f\"Size:\\nRows: {smoking_df.shape[0]}, Columns: {smoking_df.shape[1]}\")\n",
    "print(\"Smoking columns:\", smoking_df.columns.tolist(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gamers_df:\n",
    "This dataset, which I created myself from a website, contains data for 29 countries, including key metrics such as market revenue in the video games industry (in millions of dollars), internet penetration (percentage), number of gamers (in millions), mobile market revenue (in millions of dollars), yearly spending on mobile games per user (in dollars), and English proficiency (average level of English speakers). While the dataset is rich in information, it is limited in the number of countries covered. Nevertheless, it is valuable for analyzing the gaming population across different countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Display head (2 first rows)\n",
    "print(\"Gamers DataFrame:\", gamers_df.head(2), \"\\n\")\n",
    "# Size display and  features\n",
    "print(f\"Size:\\nRows: {gamers_df.shape[0]}, Columns: {gamers_df.shape[1]}\")\n",
    "print(\"Gamers columns:\", gamers_df.columns.tolist(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Edstats_df:\n",
    "This dataset contains extensive data collected in series, not limited to country-level information, making it suitable for analyzing specific details by region. For this project, we will primarily focus on analyzing the higher education population per country, filtering and selecting the most relevant series for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Display head (2 first rows)\n",
    "print(\"Students Enrolment DataFrame:\", edstats_df.head(2), \"\\n\")\n",
    "# Size display and features\n",
    "print(f\"Size:\\nRows: {edstats_df.shape[0]}, Columns: {edstats_df.shape[1]}\")\n",
    "print(\"Student enrolment columns:\", edstats_df.columns.tolist(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Students_df\n",
    "This dataset has information relevant to the number of enrolled students per country and includes various metrics related to education, such as enrollment rates, education levels, and potentially regional or demographic breakdowns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Display head (2 first rows)\n",
    "print(\"Students Enrolment DataFrame:\", students_df.head(2), \"\\n\")\n",
    "\n",
    "# Size display and features\n",
    "print(f\"Size:\\nRows: {students_df.shape[0]}, Columns: {students_df.shape[1]}\")\n",
    "print(\"Student enrolment columns:\", students_df.columns.tolist(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Processing Data\n",
    "\n",
    "We will progresively remove or handle missing values, correcting or convert data types accurately, filtering out unnecessary rows or columns, transforming data by normalizing, scaling, or aggregating to ensure consistency and usability.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coffee_df:**\n",
    "\n",
    "Now to process this dataset, we will do the following in a new dataset called **coffee2020_df**:\n",
    "\n",
    "1. Remove unnecessary features, specifically the 2016 data.\n",
    "2. Rename columns to give them clearer titles.\n",
    "3. Remove missing values.\n",
    "4. Change data type when needed, as by default is often adopted \"string\" type.\n",
    "5. Set 'Country' as the dataset index.\n",
    "\n",
    "The main reason for keeping only the 2020 information is to perform a country-to-country analysis within the same year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the coffee_df to a new DataFrame for processing\n",
    "coffee2020_df = coffee_df.copy()\n",
    "# 1. Remove the \"coffeeConsumptionByCountry_perCapitaCons2016\" feature\n",
    "coffee2020_df = coffee2020_df.drop(columns=['coffeeConsumptionByCountry_perCapitaCons2016'])\n",
    "# 2. Rename columns for clarity\n",
    "coffee2020_df = coffee2020_df.rename(columns={\n",
    "    'coffeeConsumptionByCountry_perCapitaCons2020': 'Coffee per capita in 2020 (KG)',\n",
    "    'country': 'Country'\n",
    "})\n",
    "# 3. Remove rows with missing values or \"0\"\n",
    "coffee2020_df = coffee2020_df.dropna()\n",
    "coffee2020_df = coffee2020_df[coffee2020_df['Coffee per capita in 2020 (KG)'] != 0]\n",
    "# Convert the 'Coffee per capita in 2020 (KG)' column to float\n",
    "coffee2020_df['Coffee per capita in 2020 (KG)'] = coffee2020_df['Coffee per capita in 2020 (KG)'].astype(float)\n",
    "# 5. Set 'Country' as the dataset index\n",
    "coffee2020_df = coffee2020_df.set_index('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now verify that the data has been processed correctly by using checking for missing values and printing the new features. Also we can print how many columns and rows have been remove by using the size of the original dataframe taking away the size the new dataframe as shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing (NaN) or empty (blank) values\n",
    "empty_values = (coffee2020_df == '').sum().sum()  # Count empty strings\n",
    "missing_or_empty_values = coffee2020_df.isnull().sum().sum() + empty_values\n",
    "\n",
    "print(f\"Total missing or empty values: {missing_or_empty_values}\")\n",
    "\n",
    "# Print the features (columns) of the processed dataset\n",
    "print(\"Features in coffee2020_df:\", coffee2020_df.columns.tolist())\n",
    "\n",
    "\n",
    "# Calculate and display the difference in rows and columns\n",
    "row_diff, col_diff = coffee_df.shape[0] - coffee2020_df.shape[0], coffee_df.shape[1] - coffee2020_df.shape[1]\n",
    "print(f\"Difference in rows: {row_diff}\\nDifference in columns: {col_diff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that this dataframe has been processed properly and now is ready for merging or visualization in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoking_df:**\n",
    "\n",
    "Similary, it's needed to create a new csv table called **smoking2020_df**:\n",
    "\n",
    "1. Remove unnecessary features, all the data from 2022 and 2021.\n",
    "2. Rename columns to give them clearer titles.\n",
    "3. Change data type when neededto interger.\n",
    "4. Remove missing values or empty strings per row.\n",
    "5. Set 'Country' as the dataset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a new DataFrame with only 2020 data\n",
    "smoking2020_df = smoking_df[['country', 'smokingRatesByCountry_rateBothPct2020', \n",
    "                               'smokingRatesByCountry_rateMalePct2020', \n",
    "                               'smokingRatesByCountry_rateFemalePct2020']]\n",
    "\n",
    "# 2. Rename the columns for clarity\n",
    "smoking2020_df = smoking2020_df.rename(columns={\n",
    "    'country': 'Country',\n",
    "    'smokingRatesByCountry_rateBothPct2020': 'Smoking rate in 2020(%)',\n",
    "    'smokingRatesByCountry_rateMalePct2020': 'Male smoking rate in 2020(%)',\n",
    "    'smokingRatesByCountry_rateFemalePct2020': 'Female smoking rate in 2020(%)'\n",
    "})\n",
    "\n",
    "# 3. Convert the columns to integers, coercing errors to NaN\n",
    "smoking2020_df['Smoking rate in 2020(%)'] = pd.to_numeric(smoking2020_df['Smoking rate in 2020(%)'], errors='coerce')\n",
    "smoking2020_df['Male smoking rate in 2020(%)'] = pd.to_numeric(smoking2020_df['Male smoking rate in 2020(%)'], errors='coerce')\n",
    "smoking2020_df['Female smoking rate in 2020(%)'] = pd.to_numeric(smoking2020_df['Female smoking rate in 2020(%)'], errors='coerce')\n",
    "\n",
    "# 4. Remove missing or unwanted data\n",
    "smoking2020_df = smoking2020_df.replace('', np.nan)  # Replace empty strings with NaN\n",
    "smoking2020_df = smoking2020_df.replace('0', np.nan)  # Replace '0' with NaN\n",
    "smoking2020_df = smoking2020_df.dropna()  # Drop rows with NaN values\n",
    "\n",
    "# 5. Set 'Country' as the dataset index\n",
    "smoking2020_df = smoking2020_df.set_index('Country')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the same procedure to verify  processing of this table. Concluding that the data processing has been succesfull as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing (NaN) or empty (blank) values\n",
    "empty_values = (smoking2020_df == '').sum().sum()  # Count empty strings\n",
    "missing_or_empty_values =smoking2020_df.isnull().sum().sum() + empty_values\n",
    "\n",
    "print(f\"Total missing or empty values: {missing_or_empty_values}\")\n",
    "\n",
    "# Print the features (columns) of the processed dataset\n",
    "print(\"Features in smoking2020_df:\",smoking2020_df.columns.tolist())\n",
    "\n",
    "\n",
    "# Calculate and display the difference in rows and columns\n",
    "row_diff, col_diff = smoking_df.shape[0] - smoking2020_df.shape[0], smoking_df.shape[1] -smoking2020_df.shape[1]\n",
    "print(f\"Difference in rows: {row_diff}\\nDifference in columns: {col_diff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gamers_df:**\n",
    "\n",
    "We will process the gamers_df dataset similarly, creatign a new dataframe, *gamers2019_df*, performing the following tasks:\n",
    "\n",
    "1. Remove unnecessary columns.\n",
    "2. Rename columns to give them clearer titles.\n",
    "3. Convert relevant columns to the correct data type.\n",
    "4. Remove rows with missing or incorrect data.\n",
    "5. Set 'Country' as the dataset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a new DataFrame with only the 'country' and 'Number of Gamers (millions)' columns\n",
    "gamers2019_df = gamers_df[['Country', 'Number of Gamers (millions)']]\n",
    "\n",
    "# 2. Rename the columns for clarity\n",
    "gamers2019_df = gamers2019_df.rename(columns={'Number of Gamers (millions)': 'Gamers in 2019(MM)'})\n",
    "\n",
    "# 3. Convert the 'Gamers in 2019(MM)' column to numeric, coercing errors to NaN\n",
    "gamers2019_df['Gamers in 2019(MM)'] = pd.to_numeric(gamers2019_df['Gamers in 2019(MM)'], errors='coerce')\n",
    "\n",
    "# 4. Remove rows with missing values (NaN)\n",
    "gamers2019_df = gamers2019_df.dropna()\n",
    "\n",
    "# 5. Set 'Country' as the dataset index\n",
    "gamers2019_df = gamers2019_df.set_index('Country')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we verify the dataframe and changes made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing (NaN) or empty (blank) values in gamers2019_df\n",
    "empty_values = (gamers2019_df == '').sum().sum()  # Count empty strings\n",
    "missing_or_empty_values = gamers2019_df.isnull().sum().sum() + empty_values\n",
    "\n",
    "print(f\"Total missing or empty values: {missing_or_empty_values}\")\n",
    "\n",
    "# Print the features (columns) of the processed dataset\n",
    "print(\"Features in gamers2019_df:\", gamers2019_df.columns.tolist())\n",
    "\n",
    "# Calculate and display the difference in rows and columns between original and processed DataFrame\n",
    "row_diff, col_diff = gamers_df.shape[0] - gamers2019_df.shape[0], gamers_df.shape[1] - gamers2019_df.shape[1]\n",
    "print(f\"Difference in rows: {row_diff}\\nDifference in columns: {col_diff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EdStats:**\n",
    "\n",
    "This dataframe requires to carry on a particulary more complex approach. since we first need to find what \"Series\" we want to filter first. Before following our typical processing approach. It's important to create an *\"enrolment_df\"* where we will use \"str.contains()\" method to filter all the series with the word enrolment in the Series column. \n",
    "We display the different titles in series using the \"unique()\" method, displaying every single unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the 'Series' column contains the word 'enrollment'\n",
    "enrolment_df = edstats_df['Series'][edstats_df['Series'].str.contains('enrolment', case=False, na=False)]\n",
    "\n",
    "# Get unique values from the 'Series' column that contain 'enrollment'\n",
    "unique_enrolment_df = enrolment_df.unique()\n",
    "\n",
    "# Display the list of unique strings containing 'enrollment'\n",
    "print(unique_enrolment_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this information we can conclude that we want the following series only: 'Enrolment in tertiary education, all programmes, both sexes (number)'\n",
    "\n",
    "Now we proceed to:\n",
    "1. Remove unnecessary rows (All th rows with irrelevant information).\n",
    "2. Rename columns to give them clearer titles.\n",
    "3. Remove unnecessary columns (We will only keep Country and the year 2020)\n",
    "4. Remove rows with missing or incorrect data.\n",
    "5. Convert relevant columns to the correct data type.\n",
    "6. Create a new column that handles the both years (2019 and 2020) prioritizing the most recent.\n",
    "7. Drop rows without numeric data in either 2019 and 2020.\n",
    "8. Set 'Country' as the dataset index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter edstats_df for rows where 'Series' matches the specified series exactly\n",
    "edstats2020_df = edstats_df[edstats_df['Series'] == 'Enrolment in tertiary education, all programmes, both sexes (number)']\n",
    "\n",
    "# Rename columns in edstats2020_df\n",
    "edstats2020_df = edstats2020_df.rename(columns={'Country Name': 'Region', \n",
    "                                                '2020 [YR2020]': 'Students in 2020',\n",
    "                                                '2019 [YR2019]': 'Students in 2019'\n",
    "                                                })\n",
    "\n",
    "# Keep only 'Region', 'Students in 2019' and 'Students in 2020' columns\n",
    "edstats2020_df = edstats2020_df[['Region', 'Students in 2020','Students in 2019']]\n",
    "\n",
    "# Remove any non-numeric characters from 'Students in 2020' and 'Students in 2019'\n",
    "edstats2020_df['Students in 2020'] = edstats2020_df['Students in 2020'].replace(r'[^0-9]', '', regex=True)\n",
    "edstats2020_df['Students in 2019'] = edstats2020_df['Students in 2019'].replace(r'[^0-9]', '', regex=True)\n",
    "\n",
    "# Convert 'Students in 2020' and 'Students in 2019' columns to integers or NaN\n",
    "edstats2020_df['Students in 2020'] = pd.to_numeric(edstats2020_df['Students in 2020'], errors='coerce').astype('Int64')\n",
    "edstats2020_df['Students in 2019'] = pd.to_numeric(edstats2020_df['Students in 2019'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Create 'Students in 2019-20' column with preference for 'Students in 2020' values\n",
    "edstats2020_df['Students in 2019-20'] = edstats2020_df['Students in 2020'].combine_first(edstats2020_df['Students in 2019'])\n",
    "\n",
    "# Keep only 'Region' and 'Students in 2019-20' columns\n",
    "edstats2020_df = edstats2020_df[['Region', 'Students in 2019-20']]\n",
    "\n",
    "# Drop rows where 'Students in 2019-20' is NaN\n",
    "edstats2020_df = edstats2020_df.dropna(subset=['Students in 2019-20'])\n",
    "\n",
    "# Set 'Region' as the index\n",
    "edstats2020_df = edstats2020_df.set_index('Region')\n",
    "\n",
    "\n",
    "#size display\n",
    "print(f\"Size:\\nRows: {edstats2020_df.shape[0]}, Columns: {edstats2020_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something very peculiar about this World Bank Groups dataset is the fact that it does not provide only countries but also regions. Therefore we will list all the 'regions' available and then we will proceed to create a data map after carefully choosing each countries most accurate equivalent. Better explained in the merging section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique country names in the 'Country' column of edstats2020_df\n",
    "unique_regions = edstats2020_df.index.unique()\n",
    "print(\"Unique regions in edstats2020_df:\\n\", unique_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging tables**\n",
    "\n",
    "The last step to follow is to merge \"coffee2020_df\", \"smoking2020_df\" and \"gamers2019_df\" into one single data frame called **\"habits2020_df\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'Country' without including edstats2020_df\n",
    "habits2020_df = smoking2020_df.join(gamers2019_df, how='inner', rsuffix='_gamers')\n",
    "habits2020_df = habits2020_df.join(coffee2020_df, how='inner', rsuffix='_coffee')\n",
    "\n",
    "# Display the size of the resulting DataFrame\n",
    "print(\"Size of habits2020_df:\", habits2020_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, edstats_df does not have a 'Country' column but a 'Region' instead, in order to merge smoothly this two datasets into a single \"HABITS VS EDUCATION\" dataframe. We need to add  a 'Region' column to habits2020_df and assign logical values from the \"unique_regions\" list created before.\n",
    "\n",
    "To achieve this we have made manually a map, When possible we will use the already existing Country for example, China and South Africa. otherwise we allocated it by simple proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from habits2020_df to regions in edstats2020_df\n",
    "country_to_region_mapping = {\n",
    "    'China': 'China',  # Direct match\n",
    "    'United States': 'North America',  # United States in North America\n",
    "    'Indonesia': 'East Asia & Pacific',  # Indonesia in Southeast Asia\n",
    "    'Brazil': 'Latin America & Caribbean',  # Brazil in Latin America\n",
    "    'Russia': 'Europe & Central Asia',  # Russia in Eastern Europe\n",
    "    'Japan': 'East Asia & Pacific',  # Japan in East Asia\n",
    "    'Philippines': 'East Asia & Pacific',  # Philippines in Southeast Asia\n",
    "    'Vietnam': 'East Asia & Pacific',  # Vietnam in Southeast Asia\n",
    "    'Iran': 'Middle East & North Africa',  # Iran in the Middle East\n",
    "    'Turkey': 'Europe & Central Asia',  # Turkey in Eastern Europe / Middle East\n",
    "    'Germany': 'Europe & Central Asia',  # Germany in Europe\n",
    "    'Thailand': 'East Asia & Pacific',  # Thailand in Southeast Asia\n",
    "    'United Kingdom': 'Europe & Central Asia',  # UK in Europe\n",
    "    'France': 'Europe & Central Asia',  # France in Europe\n",
    "    'South Africa': 'South Africa',  # Direct match\n",
    "    'Italy': 'Europe & Central Asia',  # Italy in Europe\n",
    "    'South Korea': 'East Asia & Pacific',  # South Korea in East Asia\n",
    "    'Spain': 'Europe & Central Asia',  # Spain in Europe\n",
    "    'Canada': 'North America',  # Canada in North America\n",
    "    'Poland': 'Europe & Central Asia',  # Poland in Europe\n",
    "    'Saudi Arabia': 'Middle East & North Africa',  # Saudi Arabia in the Middle East\n",
    "    'Australia': 'East Asia & Pacific',  # Australia in Oceania\n",
    "    'United Arab Emirates': 'Middle East & North Africa'  # UAE in the Middle East\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the map to create our 'Region' Column in a new dataframe called \"habits2020_REG\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe correctly\n",
    "habits2020_REG = habits2020_df.copy()  # Add parentheses to properly copy the DataFrame\n",
    "\n",
    "# Now, map the 'Country' (index) to 'Region' using the country_to_region_mapping\n",
    "habits2020_REG['Region'] = habits2020_REG.index.map(country_to_region_mapping)\n",
    "\n",
    "\n",
    "# Group by 'Region' and compute the mean for each region\n",
    "habits2020_REG = habits2020_REG.groupby('Region').mean()\n",
    "\n",
    "# Optional: Reset index if you want 'Region' as a column instead of the index\n",
    "habits2020_REG = habits2020_REG.reset_index()\n",
    "\n",
    "# Print or inspect the new DataFrame\n",
    "print(habits2020_REG)\n",
    "\n",
    "# Set 'Region' as the new index\n",
    "habits2020_REG.set_index('Region', inplace=True)\n",
    "\n",
    "# Display the size of the resulting DataFrame\n",
    "print(\"Size of habits2020_REG:\", habits2020_REG.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will merge habits2020_REG with edstats2020_df. Finally achieving our goal target habits_vs_education_df.\n",
    "\n",
    "***habits_vs_education_df:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge habits2020_REG and edstats2020_df on 'Region'\n",
    "habits_vs_education_df = habits2020_REG.merge(edstats2020_df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Display the merged DataFrame to verify the result\n",
    "print(habits_vs_education_df.head(1))\n",
    "\n",
    "# Display the size of the resulting DataFrame\n",
    "print(\"Size of habits_vs_education_df:\", habits_vs_education_df.shape)\n",
    "\n",
    "unique_index_values = habits_vs_education_df.index.unique()\n",
    "print(unique_index_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA VIZUALIZATION\n",
    "\n",
    "Now we will display the relevant data some of the processed and arranged data. From habits_vs_education_df we will collect the data we need for each graphic desired to be displayed, as listed below:\n",
    "\n",
    "- figure1 will display of the contrast of smoking by gender for each region or country using the dataset \"habits_vs_education_df\" since it has the smokers by gender of each region.\n",
    "- figure2 will display the 'habits' by region \n",
    "- figure3 will display the contrast between habits and students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of smokers consumption by gender per region \n",
    "\n",
    "In order to organize this data we will first create a table called 'fig1_df' which will hold only *Male smoking rate in 2020(%)* and *Female smoking rate in 2020(%)*. Then we will simplify the names, create a figure and create the bars and stack 'Female Smoking Rate' bar on top of the 'Male Smoking Rate' bar to create a visual effect of a cigarette and it's filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the table\n",
    "fig1_df = habits_vs_education_df[['Male smoking rate in 2020(%)', 'Female smoking rate in 2020(%)']]\n",
    "fig1_df.index = habits_vs_education_df.index  # Ensure Region is set as the index\n",
    "fig1_df = fig1_df.rename(columns={\n",
    "    'Male smoking rate in 2020(%)': 'Male Smoking Rate (%)',\n",
    "    'Female smoking rate in 2020(%)': 'Female Smoking Rate (%)'\n",
    "})\n",
    "\n",
    "# Create a horizontal bar chart for Female smoking rate over Male smoking rate\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot Male smoking rate bars\n",
    "male_bars = ax.barh(fig1_df.index, fig1_df['Male Smoking Rate (%)'], color='#fafafa', label='Male Smoking Rate')\n",
    "\n",
    "# Plot Female smoking rate bars over Male smoking rate\n",
    "female_bars = ax.barh(fig1_df.index, fig1_df['Female Smoking Rate (%)'], \n",
    "                      left=fig1_df['Male Smoking Rate (%)'], color='#ff7f0e', label='Female Smoking Rate')\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_title('Female vs. Male Smoking Rates by Region (2020)', fontsize=16, weight='bold', color='white')\n",
    "ax.set_xlabel('Smoking Rate (%)', fontsize=14, weight='bold', color='white')\n",
    "ax.set_ylabel('Region', fontsize=14, weight='bold', color='white')\n",
    "ax.set_facecolor('#0c0c0c')  # Inner chart background color\n",
    "fig.patch.set_facecolor('#0c0c1b')  # Outer background color\n",
    "ax.tick_params(colors='white')  # Set tick label color to white\n",
    "\n",
    "# Add legend to the right of the chart with customized font color and background\n",
    "legend = ax.legend(title='Gender', fontsize=12, title_fontsize=13, loc='center left', \n",
    "                   bbox_to_anchor=(1.05, 0.5), frameon=True)  # Enable legend frame\n",
    "\n",
    "# Customize legend background and font colors\n",
    "legend.get_frame().set_facecolor('#2f2f2f')  # Set background color\n",
    "legend.get_frame().set_edgecolor('white')    # Set edge color (optional)\n",
    "legend.get_frame().set_linewidth(1)          # Adjust frame thickness\n",
    "legend.get_title().set_color('white')        # Set title font color\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('white')  # Set label font color\n",
    "\n",
    "# Adjust layout to prevent clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Habbits rates between the Regions:\n",
    "\n",
    "Using the Smoking, Gamers and Coffee data we will normalize them in order for the highest value in each column to be one and in this way scale up each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for comparison\n",
    "normalized_smoking = habits_vs_education_df['Smoking rate in 2020(%)'] / habits_vs_education_df['Smoking rate in 2020(%)'].max()\n",
    "normalized_gamers = habits_vs_education_df['Gamers in 2019(MM)'] / habits_vs_education_df['Gamers in 2019(MM)'].max()\n",
    "normalized_coffee = habits_vs_education_df['Coffee per capita in 2020 (KG)'] / habits_vs_education_df['Coffee per capita in 2020 (KG)'].max()\n",
    "\n",
    "# Plot multi-line chart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot the lines\n",
    "ax.plot(habits_vs_education_df.index, normalized_smoking, label='Smoking Rate', marker='o', color='#1f77b4')\n",
    "ax.plot(habits_vs_education_df.index, normalized_gamers, label='Gamers', marker='s', color='#ff69b4')\n",
    "ax.plot(habits_vs_education_df.index, normalized_coffee, label='Coffee Consumption', marker='^', color='#2ca02c')\n",
    "\n",
    "# Customize chart\n",
    "ax.set_xlabel('Region', fontsize=12, color='white')  # Font color for x-axis\n",
    "ax.set_ylabel('Normalized Values of the Habits', fontsize=12, color='white')  # Font color for y-axis\n",
    "ax.set_title('Trends in Smoking, Gamers, and Coffee Consumption by Region', fontsize=16, color='white')  # Font color for title\n",
    "ax.set_xticks(range(len(habits_vs_education_df.index)))\n",
    "ax.set_xticklabels(habits_vs_education_df.index, rotation=45, ha='right', color='white')  # Font color for xticklabels\n",
    "\n",
    "# Set background color (both inner and outer)\n",
    "ax.set_facecolor('#0c0c0c')  # Inner background color\n",
    "fig.patch.set_facecolor('#0c0c1b')  # Outer background color\n",
    "ax.tick_params(colors='white')  # Set tick label color to white\n",
    "\n",
    "# Set the color of the axis lines (spines) to white\n",
    "ax.spines['top'].set_color('white')\n",
    "ax.spines['bottom'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "ax.spines['right'].set_color('white')\n",
    "\n",
    "# Move legend to the right of the plot\n",
    "legend = ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title='Habits', fontsize=12, title_fontsize=13, frameon=True)\n",
    "\n",
    "# Customize legend background and font colors\n",
    "legend.get_frame().set_facecolor('#2f2f2f')  # Set background color for legend box\n",
    "legend.get_frame().set_edgecolor('white')    # Set edge color for the legend box\n",
    "legend.get_frame().set_linewidth(1)          # Set line width for the legend box\n",
    "legend.get_title().set_color('white')        # Set legend title font color\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('white')  # Set legend labels font color\n",
    "\n",
    "# Adjust layout to prevent clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Habits by region Vs Students by region.\n",
    "\n",
    "For our last plot we will simply normalize data one more time but this time with different scalability. The main reason is that due to the challenge of different proyected data we have (Rate, Millions and KG) we will have to normalize it all to be able of contrasting the consumption per region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the specified columns to a range from 0 to 1 (for habits data)\n",
    "normalized_smoking = habits_vs_education_df['Smoking rate in 2020(%)'] / habits_vs_education_df['Smoking rate in 2020(%)'].max()\n",
    "normalized_gamers = habits_vs_education_df['Gamers in 2019(MM)'] / habits_vs_education_df['Gamers in 2019(MM)'].max()\n",
    "normalized_coffee = habits_vs_education_df['Coffee per capita in 2020 (KG)'] / habits_vs_education_df['Coffee per capita in 2020 (KG)'].max()\n",
    "\n",
    "# Normalize 'Students in 2019-20' to a range from 0 to 3\n",
    "normalized_students = habits_vs_education_df['Students in 2019-20'] / habits_vs_education_df['Students in 2019-20'].max() * 3\n",
    "\n",
    "# Create the new DataFrame fig3_df with the normalized values\n",
    "fig3_df = pd.DataFrame({\n",
    "    'Normalized Smoking Rate': normalized_smoking,\n",
    "    'Normalized Gamers': normalized_gamers,\n",
    "    'Normalized Coffee Consumption': normalized_coffee,\n",
    "    'Normalized Students': normalized_students\n",
    "})\n",
    "\n",
    "# Merge 'China' with 'East Asia & Pacific' by adding their values\n",
    "fig3_df.loc['East Asia & Pacific'] = fig3_df.loc['China'] + fig3_df.loc['East Asia & Pacific']\n",
    "fig3_df = fig3_df.drop('China', axis=0)\n",
    "\n",
    "# Create the positions for the bars (the x-axis for the bars)\n",
    "x = np.arange(len(fig3_df))  # Positions for the bars\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "# Plotting the stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot each of the habits on top of each other\n",
    "ax.bar(x, fig3_df['Normalized Smoking Rate'], width, label='Smoking Rate', color='#1f77b4')\n",
    "ax.bar(x, fig3_df['Normalized Gamers'], width, bottom=fig3_df['Normalized Smoking Rate'], label='Gamers', color='#ff69b4')\n",
    "ax.bar(x, fig3_df['Normalized Coffee Consumption'], width, bottom=fig3_df['Normalized Smoking Rate'] + fig3_df['Normalized Gamers'], label='Coffee Consumption', color='#2ca02c')\n",
    "\n",
    "# Plot the normalized students next to the stacked habits bar\n",
    "ax.bar(x + width, fig3_df['Normalized Students'], width, label='Students', color='#d62728')\n",
    "\n",
    "# Customize chart\n",
    "ax.set_xlabel('Region', fontsize=12, color='white')\n",
    "ax.set_ylabel('Normalized Values', fontsize=12, color='white')\n",
    "ax.set_title('Comparison of Habits and Students by Region', fontsize=16, color='white')\n",
    "ax.set_xticks(x + width / 2)  # Position the labels between bars\n",
    "ax.set_xticklabels(fig3_df.index, rotation=45, ha='right', color='white')\n",
    "ax.tick_params(axis='x', colors='white')  # Set the x-axis tick color to white\n",
    "ax.tick_params(axis='y', colors='white')  # Set the y-axis tick color to white\n",
    "\n",
    "# Set background color\n",
    "ax.set_facecolor('#0c0c0c')  # Inner background color\n",
    "fig.patch.set_facecolor('#0c0c1b')  # Outer background color\n",
    "\n",
    "# Add a legend to the right of the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title='Categories', fontsize=12, title_fontsize=13)\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
